{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No', 'STUDENTS_NAME', 'UFA Reg No', 'Time taken', 'Final Theory',\n",
      "       'Practical(A) out of 80', 'Oral Exam out of 20', 'Final Practical',\n",
      "       'Final Icare (Theory + Practical)', 'Hospital Internship Score',\n",
      "       'Final Score', 'Final Grade', 'ID Numbers',\n",
      "       'Hospital Internship Attended - 2', 'Start Date of Class',\n",
      "       'End Date of Class', 'Class ID', 'Year', 'Branch', 'Course',\n",
      "       'Month Of Class', 'Type of Class', 'Status',\n",
      "       'School Internship attended', 'School Internship score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load your large CSV file\n",
    "d3 = pd.read_csv('C:\\\\Users\\\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\D_Ujuzi3.csv')\n",
    "\n",
    "#reading the columns \n",
    "print(d3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        No              STUDENTS_NAME UFA Reg No       Time taken  \\\n",
      "0        1              Jacinta Onono        449             Null   \n",
      "1880  1881   Christine Nzambi Ojiambo    23-1168  51 mins 18 secs   \n",
      "1872  1873         Pande Stacy Monica     23-645             Null   \n",
      "1873  1874  Christine Michelle Watetu     23-843             Null   \n",
      "1874  1875        Kevin Mungai Munene     23-689             Null   \n",
      "\n",
      "     Final Theory Practical(A) out of 80 Oral Exam out of 20 Final Practical  \\\n",
      "0            Null                   Null                Null            Null   \n",
      "1880           86                     65                  15              80   \n",
      "1872         Null                   Null                Null            Null   \n",
      "1873         Null                   Null                Null            Null   \n",
      "1874         Null                   Null                Null            Null   \n",
      "\n",
      "     Final Icare (Theory + Practical) Hospital Internship Score  ...  \\\n",
      "0                                Null                      Null  ...   \n",
      "1880                               83                        87  ...   \n",
      "1872                             Null                      Null  ...   \n",
      "1873                             Null                      Null  ...   \n",
      "1874                             Null                      Null  ...   \n",
      "\n",
      "     End Date of Class                                           Class ID  \\\n",
      "0            7/28/2021                                               Null   \n",
      "1880        12/15/2023                     Batch 5 2023 Afternoon_Nairobi   \n",
      "1872          8/9/2023  Batch 1 2023 Advanced Web design and developme...   \n",
      "1873          8/9/2023  Batch 2 2023 Android Application development_N...   \n",
      "1874          8/9/2023  Batch 1 2023 Android Application development_N...   \n",
      "\n",
      "      Year   Branch                               Course Month Of Class  \\\n",
      "0     2021  Nairobi                            Eldercare            May   \n",
      "1880  2023  Nairobi                            Eldercare      September   \n",
      "1872  2023  Nairobi  Advanced Web design and development            May   \n",
      "1873  2023  Nairobi      Android Application development           June   \n",
      "1874  2023  Nairobi      Android Application development            May   \n",
      "\n",
      "     Type of Class     Status School Internship attended  \\\n",
      "0        Afternoon  Graduated                       Null   \n",
      "1880     Afternoon  Graduated                       Null   \n",
      "1872       Morning  Graduated                       Null   \n",
      "1873       Morning  Graduated                       Null   \n",
      "1874       Morning  Graduated                       Null   \n",
      "\n",
      "     School Internship score  \n",
      "0                       Null  \n",
      "1880                    Null  \n",
      "1872                    Null  \n",
      "1873                    Null  \n",
      "1874                    Null  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load your large CSV file\n",
    "d3 = pd.read_csv('C:\\\\Users\\\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\D_Ujuzi3.csv')\n",
    "\n",
    "# Sort the DataFrame so that 'graduated' comes first in case of duplicate admission numbers\n",
    "d3_sorted = d3.sort_values(by='Status', ascending=False)\n",
    "\n",
    "# Drop duplicates by 'Registration number', keeping the first occurrence \n",
    "filtered_d3 = d3_sorted.drop_duplicates(subset='UFA Reg No')\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file (optional)\n",
    "filtered_d3.to_csv('d3filter_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(filtered_d3.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\TECHSKILLS 360\\AppData\\Local\\Temp\\ipykernel_23372\\2559794063.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df2 = pd.read_csv('C:\\\\Users\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\d3filter_data.csv')  # Dataset 2 (Needs correction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No', 'STUDENTS_NAME', 'UFA Reg No', 'Time taken', 'Final Theory',\n",
      "       'Practical(A) out of 80', 'Oral Exam out of 20', 'Final Practical',\n",
      "       'Final Icare (Theory + Practical)', 'Hospital Internship Score',\n",
      "       'Final Score', 'Final Grade', 'ID Numbers',\n",
      "       'Hospital Internship Attended - 2', 'Start Date of Class',\n",
      "       'End Date of Class', 'Class ID', 'Year', 'Branch', 'Course',\n",
      "       'Month Of Class', 'Type of Class', 'Status',\n",
      "       'School Internship attended', 'School Internship score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('C:\\\\Users\\\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\clean_final4.csv')  # Dataset 1 (Correct dataset)\n",
    "df2 = pd.read_csv('C:\\\\Users\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\d3filter_data.csv')  # Dataset 2 (Needs correction)\n",
    "\n",
    "print(df2.columns)\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\TECHSKILLS 360\\AppData\\Local\\Temp\\ipykernel_23372\\2229507292.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df2 = pd.read_csv('C:\\\\Users\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\d3filter_data.csv')  # Dataset 2 (Needs correction)\n",
      "C:\\Users\\TECHSKILLS 360\\AppData\\Local\\Temp\\ipykernel_23372\\2229507292.py:6: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  df2 = pd.read_csv('C:\\\\Users\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\d3filter_data.csv')  # Dataset 2 (Needs correction)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['UFA Reg No', 'Status'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTECHSKILLS 360\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCLEANED UJUZI\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md3filter_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Dataset 2 (Needs correction)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Merge the two datasets on the common 'id' column\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# The suffixes allow distinguishing between the 'status' columns in both datasets\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df2, \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUFA Reg No\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStatus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUFA Reg No\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_df1\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Update the 'status' column in Dataset 2 with the correct values from Dataset 1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus_df2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus_df1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcombine_first(merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus_df2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\TECHSKILLS 360\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\TECHSKILLS 360\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TECHSKILLS 360\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['UFA Reg No', 'Status'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "# Replace 'dataset1.csv' and 'dataset2.csv' with your actual file paths\n",
    "df1 = pd.read_csv('C:\\\\Users\\\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\clean_final4.csv')  # Dataset 1 (Correct dataset)\n",
    "df2 = pd.read_csv('C:\\\\Users\\TECHSKILLS 360\\\\Desktop\\\\CLEANED UJUZI\\\\d3filter_data.csv')  # Dataset 2 (Needs correction)\n",
    "\n",
    "# Merge the two datasets on the common 'id' column\n",
    "# The suffixes allow distinguishing between the 'status' columns in both datasets\n",
    "merged_df = pd.merge(df2, df1[['UFA Reg No', 'Status']], on='UFA Reg No', how='left', suffixes=('_df2', '_df1'))\n",
    "\n",
    "# Update the 'status' column in Dataset 2 with the correct values from Dataset 1\n",
    "merged_df['Status_df2'] = merged_df['Status_df1'].combine_first(merged_df['Status_df2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
